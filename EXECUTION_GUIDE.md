# Guia de Execu√ß√£o da DAG NYC Taxi

## Configura√ß√£o Atual

- **Data de in√≠cio**: 2025-05-01
- **Data de t√©rmino**: 2025-10-31
- **Schedule**: Mensal (`@monthly`)
- **Catchup**: Ativado
- **Max runs paralelas**: 2

Isso significa que ao ativar a DAG, ela processar√° **os √∫ltimos 6 meses de 2025** (maio a outubro).

## ‚ö†Ô∏è Pr√©-requisitos

Antes de executar a DAG, certifique-se de que:

1. ‚úÖ **JARs do Spark foram baixados**
   ```bash
   cd spark-jars
   ./download_jars.sh
   cd ..
   ```
   üìã Veja detalhes em [spark-jars/README.md](spark-jars/README.md)

2. ‚úÖ **Todos os containers est√£o rodando**
   ```bash
   docker compose ps
   ```
   Deve mostrar: airflow, postgres-airflow, postgres-nyc-taxi, minio, streamlit

3. ‚úÖ **Dashboard Streamlit est√° acess√≠vel**
   - Acesse: http://localhost:8501

## Op√ß√µes de Execu√ß√£o

### Op√ß√£o 1: Processar Todos os Meses (Padr√£o Atual)

Simplesmente ative a DAG na UI do Airflow. Ela processar√° automaticamente:
- 2025-05 (Maio)
- 2025-06 (Junho)
- 2025-07 (Julho)
- 2025-08 (Agosto)
- 2025-09 (Setembro)
- 2025-10 (Outubro)
- **Total**: 6 meses

**Tempo estimado**: ~1 hora (com 2 runs paralelas)

**Acompanhar progresso**:
- üéØ Airflow UI: http://localhost:8080
- üìä Streamlit Dashboard: http://localhost:8501 (atualiza automaticamente)
- üóÑÔ∏è MinIO Console: http://localhost:9001

### Op√ß√£o 2: Processar Apenas Alguns Meses

Se voc√™ quiser processar apenas meses espec√≠ficos:

1. **Via UI do Airflow**:
   - V√° para a DAG `nyc_taxi_data_pipeline`
   - Clique em "Browse" ‚Üí "DAG Runs"
   - Clique em "Clear" nas runs que voc√™ N√ÉO quer executar
   - Isso marcar√° elas como "success" sem executar

2. **Via CLI**:
   ```bash
   # Processar apenas maio de 2025
   docker exec airflow airflow dags backfill \
       -s 2025-05-01 \
       -e 2025-05-31 \
       nyc_taxi_data_pipeline
   ```

### Op√ß√£o 3: Processar Apenas os √öltimos N Meses

Modifique a `start_date` na DAG ([dags/nyc_taxi_pipeline.py](dags/nyc_taxi_pipeline.py)):

```python
# Para processar apenas 2024
start_date=pendulum.datetime(2024, 1, 1, tz="UTC")

# Para processar apenas √∫ltimos 6 meses
start_date=pendulum.now('UTC').subtract(months=6).start_of('month')

# Para processar apenas √∫ltimos 3 meses
start_date=pendulum.now('UTC').subtract(months=3).start_of('month')
```

### Op√ß√£o 4: Executar Manualmente para Datas Espec√≠ficas

1. Na UI do Airflow, v√° para a DAG
2. Clique em "Trigger DAG"
3. Escolha "Trigger w/ config"
4. Configure a data de execu√ß√£o desejada

## Monitoramento

### Verificar Progresso

#### Via Airflow
```bash
# Ver status de todas as runs
docker exec airflow airflow dags list-runs -d nyc_taxi_data_pipeline

# Ver logs de uma task espec√≠fica
docker compose logs -f airflow | grep "ingest_data"

# Ver logs do Streamlit
docker compose logs -f streamlit
```

#### Via Dashboard Streamlit
1. Acesse http://localhost:8501
2. Use os filtros para visualizar dados conforme s√£o processados
3. M√©tricas s√£o atualizadas em tempo real

#### Via PostgreSQL
```bash
# Verificar espa√ßo em disco
docker exec postgres-nyc-taxi psql -U nyc_user -d nyc_taxi_db -c "
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;"

# Contar registros processados
docker exec postgres-nyc-taxi psql -U nyc_user -d nyc_taxi_db -c "
SELECT COUNT(*) as total_trips FROM nyc_trips_silver;"
```

### Pausar Execu√ß√£o

Se precisar pausar:

```bash
# Pausar a DAG
docker exec airflow airflow dags pause nyc_taxi_data_pipeline

# Despausar
docker exec airflow airflow dags unpause nyc_taxi_data_pipeline
```

## Acompanhando no Streamlit

Enquanto a DAG executa, voc√™ pode:

1. **Visualizar dados em tempo real** no dashboard
2. **Filtrar por data** para ver apenas dados j√° processados
3. **Explorar m√©tricas**:
   - Total de viagens
   - Receita gerada
   - Dist√¢ncia percorrida
   - Padr√µes de demanda
   - Rotas populares

**URL**: http://localhost:8501

## Troubleshooting

### Se as runs estiverem falhando

1. **Verificar logs do Airflow**:
   ```bash
   docker compose logs -f airflow
   ```

2. **Verificar se os JARs do Spark est√£o presentes**:
   ```bash
   ls -lh spark-jars/*.jar
   ```
   Deve listar: postgresql-42.6.0.jar, hadoop-aws-3.4.1.jar, aws-java-sdk-bundle-1.12.772.jar

3. **Verificar se MinIO tem espa√ßo**:
   - Acesse http://localhost:9001
   - Login: `minioadmin` / `minio@1234!`
   - Verifique o bucket `ingestion-data-lake`

4. **Verificar se PostgreSQL est√° acess√≠vel**:
   ```bash
   docker exec -it postgres-nyc-taxi psql -U nyc_user -d nyc_taxi_db -c "SELECT 1;"
   ```

5. **Verificar mem√≥ria do Spark**:
   ```bash
   docker stats airflow
   ```
   Se falhar com OutOfMemory, aumente mem√≥ria do Docker (Settings ‚Üí Resources)

### Dashboard Streamlit n√£o mostra dados

```bash
# Verificar logs do Streamlit
docker compose logs streamlit

# Verificar se h√° dados no PostgreSQL
docker exec -it postgres-nyc-taxi psql -U nyc_user -d nyc_taxi_db -c "
SELECT COUNT(*) FROM nyc_trips_silver;"

# Reiniciar Streamlit
docker compose restart streamlit
```

### ClassNotFoundException ou erros de Spark

‚ö†Ô∏è **Causa**: JARs n√£o foram baixados
**Solu√ß√£o**:
```bash
cd spark-jars
./download_jars.sh
cd ..
docker compose restart airflow
```

### Se quiser recome√ßar do zero

```bash
# Parar containers
docker compose down

# Remover volumes (APAGA TODOS OS DADOS!)
docker compose down -v

# Baixar JARs novamente
cd spark-jars
./download_jars.sh
cd ..

# Reconstruir e iniciar
docker compose up -d --build
```

## Estimativas de Recursos

Para processar 6 meses de dados NYC Taxi (Mai-Out 2025):

- **Espa√ßo em disco**: ~2-3 GB (dados brutos ~400 MB + processados)
- **RAM**: M√≠nimo 8 GB recomendado
- **Tempo**:
  - Ingest√£o: ~3-5 min por m√™s
  - Transforma√ß√£o: ~5-10 min por m√™s
  - dbt: ~1-2 min por m√™s
  - **Total**: ~10-17 min por m√™s √ó 6 meses = **1-1.5 horas**

Com 2 runs paralelas: **~30-60 minutos total**

## Recomenda√ß√£o

Para o primeiro teste, recomendo:

1. ‚úÖ Processar apenas **1 m√™s** primeiro para validar (por exemplo, outubro)
2. ‚úÖ Verificar dados no PostgreSQL e no Dashboard Streamlit
3. ‚úÖ Confirmar que tudo est√° funcionando
4. ‚úÖ Depois liberar para processar todos os 6 meses

Para testar com apenas 1 m√™s, modifique temporariamente a DAG:

```python
start_date=pendulum.datetime(2025, 10, 1, tz="UTC")  # Apenas outubro
end_date=pendulum.datetime(2025, 10, 31, tz="UTC")
```

**Expans√£o Futura**: Se precisar de mais dados hist√≥ricos, ajuste:

```python
# Para processar todo 2024 e 2025
start_date=pendulum.datetime(2024, 1, 1, tz="UTC")
end_date=pendulum.datetime(2025, 10, 31, tz="UTC")
max_active_runs=3  # Aumentar paralelismo
```

## URLs R√°pidas

- üéØ **Airflow UI**: http://localhost:8080
- üìä **Streamlit Dashboard**: http://localhost:8501
- üóÑÔ∏è **MinIO Console**: http://localhost:9001
- üìö **dbt Docs**: http://localhost:8001 (ap√≥s `dbt docs serve`)

## Pr√≥ximos Passos

Ap√≥s execu√ß√£o bem-sucedida:

1. ‚úÖ Explore o **Dashboard Streamlit** com diferentes filtros
2. ‚úÖ Consulte dados no **PostgreSQL** diretamente
3. ‚úÖ Gere **documenta√ß√£o do dbt** (`dbt docs generate && dbt docs serve`)
4. ‚úÖ Crie **novos modelos Gold** em `dbt_project/models/gold/`
5. ‚úÖ Adicione **mais testes** em `dbt_project/models/*/schema.yml`
6. ‚úÖ **Customize o dashboard** editando `streamlit_app/app.py`