# ğŸš• NYC Taxi Data Pipeline

![Python](https://img.shields.io/badge/python-3.11-blue)
![Airflow](https://img.shields.io/badge/airflow-2.9.1-green)
![Spark](https://img.shields.io/badge/spark-3.5-orange)
![dbt](https://img.shields.io/badge/dbt-1.7-red)
![Docker](https://img.shields.io/badge/docker-compose-blue)
![License](https://img.shields.io/badge/license-MIT-green)

Pipeline de dados completo de ponta a ponta para anÃ¡lise dos dados de tÃ¡xi de NYC (New York City Taxi and Limousine Commission). Implementa a arquitetura Medallion (Bronze â†’ Silver â†’ Gold) orquestrada com Apache Airflow.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura](#arquitetura)
- [Stack TecnolÃ³gica](#stack-tecnolÃ³gica)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Como Usar](#como-usar)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Pipeline de Dados](#pipeline-de-dados)
- [Comandos Ãšteis](#comandos-Ãºteis)
- [Dashboard](#dashboard)
- [Contribuindo](#contribuindo)
- [LicenÃ§a](#licenÃ§a)
- [Autor](#autor)

## ğŸ¯ VisÃ£o Geral

Este projeto demonstra a construÃ§Ã£o de um data pipeline moderno e escalÃ¡vel utilizando as principais ferramentas do ecossistema de engenharia de dados:

- **IngestÃ£o automatizada** de dados pÃºblicos do NYC TLC
- **Processamento distribuÃ­do** com Apache Spark para grandes volumes
- **TransformaÃ§Ãµes SQL** modulares e testÃ¡veis com dbt
- **OrquestraÃ§Ã£o** robusta com Apache Airflow
- **Armazenamento** em camadas (Data Lake + Data Warehouse)
- **VisualizaÃ§Ã£o** interativa com Streamlit

### Arquitetura Medallion

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Source    â”‚â”€â”€â”€â”€â–¶â”‚    Bronze    â”‚â”€â”€â”€â”€â–¶â”‚    Silver    â”‚â”€â”€â”€â”€â–¶â”‚     Gold     â”‚
â”‚  (NYC TLC)  â”‚     â”‚   (MinIO)    â”‚     â”‚ (PostgreSQL) â”‚     â”‚ (PostgreSQL) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Public API         Raw Data Layer     Clean & Enriched    Aggregated Metrics
```

- **Bronze (Raw)**: Dados brutos, exatamente como extraÃ­dos da fonte
- **Silver (Refined)**: Dados limpos, validados, enriquecidos e normalizados
- **Gold (Curated)**: Dados agregados e otimizados para anÃ¡lise e BI

## ğŸ—ï¸ Arquitetura

### Containers

O ambiente completo roda em containers Docker:

| Container | DescriÃ§Ã£o | Porta | Acesso |
|-----------|-----------|-------|--------|
| **airflow** | Apache Airflow (orquestrador) | `8080` | http://localhost:8080 |
| **postgres-airflow** | PostgreSQL (metadados Airflow) | `5432` | Interno |
| **postgres-nyc-taxi** | PostgreSQL (Data Warehouse) | `5433` | localhost:5433 |
| **minio** | MinIO (Data Lake S3-compatible) | `9000`, `9001` | http://localhost:9001 |
| **streamlit** | Dashboard interativo | `8501` | http://localhost:8501 |

### Acessos RÃ¡pidos

- **Airflow UI**: http://localhost:8080
  - User: `admin`
  - Password: `docker exec airflow cat /opt/airflow/standalone_admin_password.txt`
- **MinIO Console**: http://localhost:9001
  - User: `minioadmin`
  - Password: `minio@1234!`
- **Streamlit Dashboard**: http://localhost:8501
- **PostgreSQL**: `localhost:5433`
  - Database: `nyc_taxi_db`
  - User: `nyc_user`
  - Password: `nyc_pass_123`

## ğŸ› ï¸ Stack TecnolÃ³gica

- **OrquestraÃ§Ã£o**: Apache Airflow 2.9.1
- **Processamento**: Apache Spark 3.5 (PySpark)
- **TransformaÃ§Ã£o**: dbt 1.7 (data build tool)
- **Data Lake**: MinIO (S3-compatible storage)
- **Data Warehouse**: PostgreSQL 15
- **VisualizaÃ§Ã£o**: Streamlit
- **ContainerizaÃ§Ã£o**: Docker & Docker Compose
- **Linguagem**: Python 3.11

## ğŸ“¦ PrÃ©-requisitos

- **Docker**: versÃ£o 20.10 ou superior
- **Docker Compose**: versÃ£o 2.0 ou superior
- **Recursos mÃ­nimos**:
  - 8GB RAM disponÃ­vel para Docker
  - 10GB espaÃ§o em disco livre
  - 4 CPU cores (recomendado)

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/FelipePiva03/Data-Pipeline.git
cd Data-Pipeline
```

### 2. Configure as variÃ¡veis de ambiente

```bash
# Copie o arquivo de exemplo
cp .env.example .env

# (Opcional) Edite o .env para customizar credenciais
nano .env
```

âš ï¸ **Importante**: Para produÃ§Ã£o, altere as senhas padrÃ£o!

### 3. Inicie os containers

```bash
# Build e start de todos os serviÃ§os
docker compose up -d --build

# Verificar se todos estÃ£o rodando
docker compose ps
```

Aguarde ~2-3 minutos para todos os serviÃ§os iniciarem.

### 4. Verifique a inicializaÃ§Ã£o

```bash
# Acompanhar logs do Airflow
docker compose logs -f airflow

# Pressione Ctrl+C quando ver "Airflow is ready"
```

## ğŸ’¡ Como Usar

### Quick Start

1. **Obtenha a senha do Airflow**:
```bash
docker exec airflow cat /opt/airflow/standalone_admin_password.txt
```

2. **Acesse a UI do Airflow**: http://localhost:8080
   - Login com `admin` e a senha obtida

3. **Execute a DAG**:
   - Localize `nyc_taxi_data_pipeline`
   - Ative a DAG (toggle Ã  esquerda)
   - Clique em "Trigger DAG"
   - Acompanhe no Graph View

4. **Acesse o Dashboard**: http://localhost:8501

### Consultar Dados Processados

```bash
# Conectar ao PostgreSQL
docker exec -it postgres-nyc-taxi psql -U nyc_user -d nyc_taxi_db

# Ver tabelas
\dt

# Consultar dados Silver
SELECT
    partition_year,
    partition_month,
    COUNT(*) as total_trips,
    ROUND(AVG(trip_distance)::numeric, 2) as avg_distance,
    ROUND(AVG(total_amount)::numeric, 2) as avg_fare
FROM nyc_trips_silver
GROUP BY partition_year, partition_month
ORDER BY partition_year, partition_month;

# Consultar agregaÃ§Ãµes Gold
SELECT * FROM daily_trip_stats ORDER BY trip_date DESC LIMIT 20;
```

## ğŸ“ Estrutura do Projeto

```
Data-Pipeline/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ nyc_taxi_pipeline.py          # DAG principal do Airflow
â”‚
â”œâ”€â”€ dbt_project/                      # TransformaÃ§Ãµes SQL com dbt
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ silver/                   # Camada Silver (limpeza)
â”‚   â”‚   â””â”€â”€ gold/                     # Camada Gold (agregaÃ§Ãµes)
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ scripts/                          # Scripts Python do pipeline
â”‚   â”œâ”€â”€ ingestor.py                   # Bronze: IngestÃ£o de dados
â”‚   â”œâ”€â”€ transformer.py                # Silver: TransformaÃ§Ã£o Spark
â”‚   â”œâ”€â”€ init_dbt.py                   # Setup do dbt
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py                 # ConfiguraÃ§Ã£o de logs
â”‚       â””â”€â”€ spark_session.py          # Spark session builder
â”‚
â”œâ”€â”€ streamlit_app/                    # Dashboard interativo
â”‚   â”œâ”€â”€ app.py                        # AplicaÃ§Ã£o Streamlit
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ spark-jars/                       # JARs para Spark
â”‚   â”œâ”€â”€ postgresql-42.6.0.jar
â”‚   â”œâ”€â”€ hadoop-aws-3.4.1.jar
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ .env.example                      # Exemplo de variÃ¡veis de ambiente
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml                # OrquestraÃ§Ã£o dos serviÃ§os
â”œâ”€â”€ Dockerfile                        # Imagem customizada Airflow
â”œâ”€â”€ LICENSE                           # LicenÃ§a MIT
â”œâ”€â”€ requirements.txt                  # DependÃªncias Python
â”œâ”€â”€ README.md                         # Este arquivo
â”œâ”€â”€ QUICK_START.md                    # Guia rÃ¡pido
â””â”€â”€ EXECUTION_GUIDE.md                # Guia detalhado de execuÃ§Ã£o
```

## ğŸ”„ Pipeline de Dados

### Fluxo de ExecuÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Ingest Data   â”‚  Download dos dados â†’ MinIO (Bronze)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. dbt: Create Silver   â”‚  Criar schema da tabela Silver
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Transform Data    â”‚  Spark: Limpar e enriquecer â†’ PostgreSQL
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. dbt: Create Gold    â”‚  Criar agregaÃ§Ãµes (Gold)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. dbt: Test Quality     â”‚  Executar testes de qualidade
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. dbt: Generate Docs    â”‚  Gerar documentaÃ§Ã£o
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detalhes das Camadas

#### ğŸ¥‰ Bronze Layer - IngestÃ£o ([ingestor.py](scripts/ingestor.py))
- **Fonte**: [NYC Taxi & Limousine Commission](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
- **Dados**: Yellow Taxi Trip Records (Parquet) + Zone Lookup (CSV)
- **Destino**: MinIO bucket `ingestion-data-lake/bronze/`
- **CaracterÃ­sticas**: Dados imutÃ¡veis, particionados por ano/mÃªs

#### ğŸ¥ˆ Silver Layer - TransformaÃ§Ã£o ([transformer.py](scripts/transformer.py))
- **Processamento**: PySpark com otimizaÃ§Ãµes
- **OperaÃ§Ãµes**:
  - ValidaÃ§Ã£o de tipos e formatos
  - Filtros de qualidade (distÃ¢ncia > 0, valores > 0)
  - Enriquecimento com dados geogrÃ¡ficos (boroughs, zones)
  - AdiÃ§Ã£o de metadados (timestamp de processamento)
- **Destino**: PostgreSQL `nyc_trips_silver`

#### ğŸ¥‡ Gold Layer - AgregaÃ§Ãµes (dbt)
- **Modelos**:
  - `daily_trip_stats`: EstatÃ­sticas diÃ¡rias por borough
  - `hourly_demand_patterns`: PadrÃµes de demanda por hora/dia da semana
- **Features**: Incrementais, testados, documentados
- **Destino**: PostgreSQL schema `public`

## ğŸ¨ Dashboard

O projeto inclui um dashboard interativo desenvolvido com Streamlit que permite:

- ğŸ“Š Visualizar mÃ©tricas principais (viagens, receita, distÃ¢ncia)
- ğŸ“ˆ Analisar tendÃªncias temporais
- ğŸ—ºï¸ Explorar rotas populares
- ğŸ’° Acompanhar receita e gorjetas
- ğŸ™ï¸ Comparar performance por bairro
- â° Identificar padrÃµes de demanda

Acesse em: http://localhost:8501

## ğŸ› ï¸ Comandos Ãšteis

### Docker

```bash
# Parar todos os containers
docker compose down

# Parar e remover volumes (CUIDADO: apaga dados!)
docker compose down -v

# Restart de um serviÃ§o especÃ­fico
docker compose restart airflow

# Ver logs
docker compose logs -f airflow
docker compose logs -f streamlit

# Verificar recursos
docker stats
```

### Airflow CLI

```bash
# Listar DAGs
docker exec airflow airflow dags list

# Listar runs
docker exec airflow airflow dags list-runs -d nyc_taxi_data_pipeline

# Testar uma task
docker exec airflow airflow tasks test nyc_taxi_data_pipeline ingest_data 2025-05-01

# Pausar/Despausar DAG
docker exec airflow airflow dags pause nyc_taxi_data_pipeline
docker exec airflow airflow dags unpause nyc_taxi_data_pipeline
```

### dbt

```bash
# Entrar no container
docker exec -it airflow bash

# Navegar para o projeto
cd /opt/airflow/dbt_project

# Configurar ambiente
export DBT_PROFILES_DIR=/opt/airflow/dbt_project

# Executar modelos
dbt run --select silver
dbt run --select gold

# Executar testes
dbt test

# Gerar e servir documentaÃ§Ã£o
dbt docs generate
dbt docs serve --port 8001
```

### PostgreSQL

```bash
# Conectar ao banco
docker exec -it postgres-nyc-taxi psql -U nyc_user -d nyc_taxi_db

# Ver tamanho das tabelas
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname IN ('public')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

# Sair
\q
```

## ğŸ‘¤ Autor

**Felipe Piva**

- GitHub: [@FelipePiva03](https://github.com/FelipePiva03)
- LinkedIn: [Felipe Piva](https://linkedin.com/in/felipe-piva-developer)
- Email: felipepiva02@gmail.com

## ğŸ“š ReferÃªncias

- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [dbt Documentation](https://docs.getdbt.com/)
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [NYC TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)

---

â­ Se este projeto foi Ãºtil, considere dar uma estrela!
